{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcuyF5GEbr7x"
      },
      "source": [
        "# Generación de Texto con LSTM usando 'Cien Años de Soledad'\n",
        "\n",
        "En este cuaderno, vamos a implementar un modelo LSTM que será entrenado usando el texto del libro 'Cien Años de Soledad' de Gabriel García Márquez.\n",
        "El objetivo es que el modelo aprenda el estilo literario y sea capaz de generar texto similar al del autor.\n",
        "\n",
        "## Requisitos previos\n",
        "- Python 3.7+\n",
        "- TensorFlow\n",
        "- Numpy\n",
        "- Matplotlib\n",
        "\n",
        "## Objetivo\n",
        "1. Preprocesar el texto de 'Cien Años de Soledad'.\n",
        "2. Implementar un modelo LSTM para la generación de texto.\n",
        "3. Entrenar el modelo y generar texto nuevo."
      ],
      "id": "ZcuyF5GEbr7x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA6-eMqXbr7z"
      },
      "source": [
        "## 1. Cargando y Preprocesando el Texto\n",
        "Cargaremos el texto de 'Cien Años de Soledad' y lo preprocesaremos para convertirlo en secuencias de texto adecuadas para el entrenamiento del modelo LSTM."
      ],
      "id": "HA6-eMqXbr7z"
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "# Cargar el texto de 'Cien Años de Soledad'\n",
        "url = 'https://raw.githubusercontent.com/Izainea/nlp_ean/main/Datos/Datos%20Crudos/CAS.txt'\n",
        "response = requests.get(url)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    text = response.text[:30000]\n",
        "else:\n",
        "    print('Error al descargar el archivo.')\n",
        "\n",
        "#Creamos las secuencias usando el tokenizador de nltk\n",
        "\n",
        "tokens=nltk.word_tokenize(text)\n",
        "\n",
        "n=10\n",
        "\n",
        "input_sequences=[]\n",
        "\n",
        "for i in range(n,len(tokens)):\n",
        "    n_gram=tokens[i-n:i]\n",
        "    input_sequences.append(n_gram)\n"
      ],
      "metadata": {
        "id": "XV1o7vHCcEri",
        "outputId": "3003aba8-2a06-4078-99db-998eb5a53f75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "XV1o7vHCcEri",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81a580fc",
      "metadata": {
        "id": "81a580fc",
        "outputId": "08f365db-3f45-46a3-80f5-9d751b89e24a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50040, 9), (50040, 1822))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "corpus= [' '.join(n_gram) for n_gram in input_sequences]\n",
        "\n",
        "# Tokenizar el texto\n",
        "tokenizer = Tokenizer(filters='')\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "print(tokenizer.word_index[','])\n",
        "\n",
        "# Convertir texto en secuencias de palabras\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)\n",
        "\n",
        "# Padding para igualar las secuencias\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre')\n",
        "\n",
        "# Dividir en características y etiquetas\n",
        "X, y = input_sequences[:,:-1], input_sequences[:,-1]\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=total_words)\n",
        "\n",
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr_N8l1ubr71"
      },
      "source": [
        "## 2. Creando el Modelo LSTM\n",
        "Ahora crearemos el modelo LSTM que será entrenado para predecir la siguiente palabra en una secuencia, basado en el estilo literario del libro."
      ],
      "id": "mr_N8l1ubr71"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2RVKdIoHbr72",
        "outputId": "ea45e155-a7ad-40b6-b396-a0a99b78b3f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 9, 8)              14576     \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 32)                1312      \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1822)              60126     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76014 (296.93 KB)\n",
            "Trainable params: 76014 (296.93 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SimpleRNN\n",
        "\n",
        "\n",
        "# Crear el modelo RNN\n",
        "model_rnn = Sequential([\n",
        "    Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=8, input_length=max_sequence_len-1),\n",
        "    SimpleRNN(32),\n",
        "    Dense(len(tokenizer.word_index)+1, activation='softmax')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Compilar el modelo\n",
        "model_rnn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Resumen del modelo\n",
        "model_rnn.summary()"
      ],
      "id": "2RVKdIoHbr72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0LlzuSlbr72"
      },
      "source": [
        "## 3. Entrenando el Modelo\n",
        "Entrenaremos el modelo durante 100 épocas para que aprenda las secuencias de texto y las relaciones entre palabras."
      ],
      "id": "j0LlzuSlbr72"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UAZ3OdRAbr72",
        "outputId": "42426bda-62ab-45bb-abcf-9c3c3bbf4e53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1564/1564 [==============================] - 8s 4ms/step - loss: 5.6649 - accuracy: 0.0809\n",
            "Epoch 2/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 4.9988 - accuracy: 0.1119\n",
            "Epoch 3/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 4.6064 - accuracy: 0.1426\n",
            "Epoch 4/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 4.2487 - accuracy: 0.1727\n",
            "Epoch 5/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 3.9128 - accuracy: 0.2106\n",
            "Epoch 6/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 3.5956 - accuracy: 0.2576\n",
            "Epoch 7/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 3.2924 - accuracy: 0.3102\n",
            "Epoch 8/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 3.0164 - accuracy: 0.3598\n",
            "Epoch 9/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 2.7699 - accuracy: 0.4084\n",
            "Epoch 10/10\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 2.5577 - accuracy: 0.4494\n"
          ]
        }
      ],
      "source": [
        "# Entrenar el modelo\n",
        "history = model_rnn.fit(X, y, epochs=10, verbose=1)"
      ],
      "id": "UAZ3OdRAbr72"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3MBcB8qbr73"
      },
      "source": [
        "## 4. Generación de Texto\n",
        "Una vez que el modelo esté entrenado, podemos usarlo para generar texto nuevo en el estilo de 'Cien Años de Soledad'."
      ],
      "id": "C3MBcB8qbr73"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "XYvMNONqbr73",
        "outputId": "371038cf-7a70-4c05-9d17-033c76a8d48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 151ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "muchos años después , no le permitía derribar un tibio olor de sangre . josé arcadio buendía , que aún no acababa de agua por tratar de cerdo a macondo , y el cuartito del galeón , y allí penetraron al bosque por un enorme calabazo lleno de melquíades . « se pronto\n"
          ]
        }
      ],
      "source": [
        "def generar_texto(model, tokenizer, seed_text, max_sequence_len, n_words):\n",
        "    for _ in range(n_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Generar texto\n",
        "print(generar_texto(model_rnn, tokenizer, 'muchos años después', max_sequence_len, 50))"
      ],
      "id": "XYvMNONqbr73"
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "history = model_rnn.fit(X, y, epochs=20, verbose=1)"
      ],
      "metadata": {
        "id": "wWUr5-DJe5-i",
        "outputId": "60ccfc97-b7c9-4763-a704-956851d21af0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "wWUr5-DJe5-i",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 2.3752 - accuracy: 0.4822\n",
            "Epoch 2/20\n",
            "1564/1564 [==============================] - 7s 5ms/step - loss: 2.2202 - accuracy: 0.5113\n",
            "Epoch 3/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 2.0851 - accuracy: 0.5404\n",
            "Epoch 4/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.9705 - accuracy: 0.5626\n",
            "Epoch 5/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.8716 - accuracy: 0.5828\n",
            "Epoch 6/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.7855 - accuracy: 0.5992\n",
            "Epoch 7/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.7092 - accuracy: 0.6161\n",
            "Epoch 8/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.6434 - accuracy: 0.6294\n",
            "Epoch 9/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.5827 - accuracy: 0.6422\n",
            "Epoch 10/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.5295 - accuracy: 0.6538\n",
            "Epoch 11/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.4817 - accuracy: 0.6644\n",
            "Epoch 12/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.4362 - accuracy: 0.6776\n",
            "Epoch 13/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.3965 - accuracy: 0.6836\n",
            "Epoch 14/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.3587 - accuracy: 0.6939\n",
            "Epoch 15/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.3244 - accuracy: 0.6994\n",
            "Epoch 16/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.2919 - accuracy: 0.7102\n",
            "Epoch 17/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.2622 - accuracy: 0.7168\n",
            "Epoch 18/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.2337 - accuracy: 0.7208\n",
            "Epoch 19/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.2083 - accuracy: 0.7275\n",
            "Epoch 20/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.1842 - accuracy: 0.7333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_texto(model_rnn, tokenizer, 'muchos años después', max_sequence_len, 50))"
      ],
      "metadata": {
        "id": "8ECDAH_JfDAv",
        "outputId": "d97c717b-7338-4cc8-bc72-5f5116bef136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8ECDAH_JfDAv",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "muchos años después , el coronel aureliano buendía , la única posibilidad de contacto con la civilización era la puerta del cuartito , y un chaleco de terciopelo patinado por el verdín de los pájaros . de modo que dotó de herramientas de desmonte y armas de cacería a los mismos hombres que\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenar el modelo\n",
        "history = model_rnn.fit(X, y, epochs=20, verbose=1)"
      ],
      "metadata": {
        "id": "gFWE0CUsfFpk",
        "outputId": "bc133f69-316a-4dc7-d6f3-70cb191c1f58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "gFWE0CUsfFpk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1564/1564 [==============================] - 7s 5ms/step - loss: 1.1624 - accuracy: 0.7378\n",
            "Epoch 2/20\n",
            "1564/1564 [==============================] - 7s 5ms/step - loss: 1.1417 - accuracy: 0.7422\n",
            "Epoch 3/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.1218 - accuracy: 0.7471\n",
            "Epoch 4/20\n",
            "1564/1564 [==============================] - 7s 5ms/step - loss: 1.1033 - accuracy: 0.7524\n",
            "Epoch 5/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0852 - accuracy: 0.7547\n",
            "Epoch 6/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0682 - accuracy: 0.7573\n",
            "Epoch 7/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0535 - accuracy: 0.7626\n",
            "Epoch 8/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0383 - accuracy: 0.7655\n",
            "Epoch 9/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0244 - accuracy: 0.7698\n",
            "Epoch 10/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 1.0106 - accuracy: 0.7720\n",
            "Epoch 11/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.9981 - accuracy: 0.7746\n",
            "Epoch 12/20\n",
            "1564/1564 [==============================] - 7s 4ms/step - loss: 0.9855 - accuracy: 0.7777\n",
            "Epoch 13/20\n",
            "1432/1564 [==========================>...] - ETA: 0s - loss: 0.9721 - accuracy: 0.7815"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generar_texto(model_rnn, tokenizer, 'muchos años después', max_sequence_len, 50))"
      ],
      "metadata": {
        "id": "eHqGDJLvf7bH"
      },
      "id": "eHqGDJLvf7bH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zpS6rA_Df-TZ"
      },
      "id": "zpS6rA_Df-TZ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}